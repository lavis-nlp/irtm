#
#          IRTM TEXT MAPPER CONFIGURATION
#    -----------------------------------------
#
#        see the default.yml for comments
#

text_encoder: bert-base-cased

wandb_args:
  project: irtm-text
  log_model: false

trainer_args:
  gpus: 1
  # this is overwritten if needed
  fast_dev_run: false
  # accumulation logic is controlled by batch size
  accumulate_grad_batches: 1

  # validation:
  # we run a full validation before fitting
  num_sanity_val_steps: 0
  check_val_every_n_epoch: 1
  log_every_n_steps: 5

# clipping logic is implemented in irtm
# (see mapper forward pass)
clip_val: 1

checkpoint_args:
  mode: max
  monitor: inductive/both.realistic.hits_at_10
  save_top_k: 10

early_stopping_args:
  mode: max
  monitor: inductive/both.realistic.hits_at_10

dataloader_train_args:
  num_workers: 0
  shuffle: true

dataloader_valid_args:
  num_workers: 0

dataloader_test_args:
  num_workers: 0

