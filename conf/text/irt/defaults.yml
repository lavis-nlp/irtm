#
#          IRTM TEXT MAPPER CONFIGURATION
#    -----------------------------------------
#
#        see the default.yml for comments
#
valid_split: 0.9
text_encoder: bert-base-cased

split_text_dataset: false

wandb_args:
  project: irtm-text
  log_model: false

trainer_args:
  # NO TOUCHY AREA
  # --------------------
  # even when training on a single
  # gpu - these settings apply
  # to ensure horovod.init()
  gpus: 1
  distributed_backend: horovod
  replace_sampler_ddp: false
  # this is overwritten if needed
  fast_dev_run: false
  # accumulation logic is controlled
  # by the batch size
  accumulate_grad_batches: 1
  # --------------------

  # clipping logic is implemented in irtm
  # (see mapper forward pass)
  gradient_clip_val: 1
  check_val_every_n_epoch: 2
  log_every_n_steps: 5

checkpoint_args:
  mode: max
  monitor: inductive/hits_at_k/both/avg/10
  save_top_k: 10

dataloader_train_args:
  num_workers: 0
  shuffle: true

dataloader_valid_args:
  num_workers: 0

dataloader_test_args:
  num_workers: 0

